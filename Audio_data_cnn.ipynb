{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "lAQ0etwr76Vl",
    "outputId": "fecfeac8-10a8-45e0-8bb3-f82b85c23227"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 2.x selected.\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 2.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dCakh4On8FIB"
   },
   "outputs": [],
   "source": [
    "# !pip install memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_fkYk3kS7fxa"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from memory_profiler import memory_usage\n",
    "import os\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R0Z46sRt7yIO"
   },
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# !apt-get install libav-tools -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZTbJ16zO8Omt"
   },
   "outputs": [],
   "source": [
    "# !wget https://www.dropbox.com/s/e5q1vvnncy0djlx/fold1.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kOJDCLSD9JwY"
   },
   "outputs": [],
   "source": [
    "# !unzip fold1.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7mw-EqvV-UE-"
   },
   "outputs": [],
   "source": [
    "# !rm -rf /content/__MACOSX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jDj5P9r1-slU"
   },
   "outputs": [],
   "source": [
    "# !rm fold1.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5yG3AHnZ_h41"
   },
   "outputs": [],
   "source": [
    "# !pip install path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RBbBivlE-2WC"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow.keras.backend as K\n",
    "import librosa\n",
    "import librosa.display\n",
    "import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import figure\n",
    "import gc\n",
    "from path import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VQbsR2MR_f12"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.mkdir('train')\n",
    "os.mkdir('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CCdnvhap_1al"
   },
   "outputs": [],
   "source": [
    "def create_spectrogram(filename,name):\n",
    "    plt.interactive(False)\n",
    "    clip, sample_rate = librosa.load(filename, sr=None)\n",
    "    fig = plt.figure(figsize=[0.72,0.72])\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.axes.get_xaxis().set_visible(False)\n",
    "    ax.axes.get_yaxis().set_visible(False)\n",
    "    ax.set_frame_on(False)\n",
    "    S = librosa.feature.melspectrogram(y=clip, sr=sample_rate)\n",
    "    librosa.display.specshow(librosa.power_to_db(S, ref=np.max))\n",
    "    filename  = '/content/train/' + name + '.jpg'\n",
    "    plt.savefig(filename, dpi=400, bbox_inches='tight',pad_inches=0)\n",
    "    plt.close()    \n",
    "    fig.clf()\n",
    "    plt.close(fig)\n",
    "    plt.close('all')\n",
    "    del filename,name,clip,sample_rate,fig,ax,S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9xMstZFrAGPD",
    "outputId": "17ebf74c-5b01-418d-b16e-cf5f04ffa47b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob('./train/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nfn5a1wUAJpP"
   },
   "outputs": [],
   "source": [
    "file_list=list(glob(\"./fold1/*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "bQ-KAGVuA3bx",
    "outputId": "20140353-f03d-4860-b92d-5ffc6d0d644b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n"
     ]
    }
   ],
   "source": [
    "for i,file in enumerate(file_list):\n",
    "    print(i)\n",
    "    filename,name = file,file.split('/')[-1].split('.')[0]\n",
    "    create_spectrogram(filename,name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6awUn1HPBmlz"
   },
   "outputs": [],
   "source": [
    "# !wget https://www.dropbox.com/s/6bhm4sfumk5p8w4/UrbanSound8K.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s2qmdBlmB2x0"
   },
   "outputs": [],
   "source": [
    "labels=pd.read_csv('/content/UrbanSound8K.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "id": "1gjyX2nmFcKB",
    "outputId": "ebda7957-9d87-458a-f767-1e7eb5bfd44a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slice_file_name</th>\n",
       "      <th>fsID</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>salience</th>\n",
       "      <th>fold</th>\n",
       "      <th>classID</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100032-3-0-0.wav</td>\n",
       "      <td>100032</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.317551</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100263-2-0-117.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>58.500000</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100263-2-0-121.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>60.500000</td>\n",
       "      <td>64.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100263-2-0-126.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100263-2-0-137.wav</td>\n",
       "      <td>100263</td>\n",
       "      <td>68.500000</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8727</th>\n",
       "      <td>99812-1-2-0.wav</td>\n",
       "      <td>99812</td>\n",
       "      <td>159.522205</td>\n",
       "      <td>163.522205</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>car_horn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8728</th>\n",
       "      <td>99812-1-3-0.wav</td>\n",
       "      <td>99812</td>\n",
       "      <td>181.142431</td>\n",
       "      <td>183.284976</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>car_horn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8729</th>\n",
       "      <td>99812-1-4-0.wav</td>\n",
       "      <td>99812</td>\n",
       "      <td>242.691902</td>\n",
       "      <td>246.197885</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>car_horn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8730</th>\n",
       "      <td>99812-1-5-0.wav</td>\n",
       "      <td>99812</td>\n",
       "      <td>253.209850</td>\n",
       "      <td>255.741948</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>car_horn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8731</th>\n",
       "      <td>99812-1-6-0.wav</td>\n",
       "      <td>99812</td>\n",
       "      <td>332.289233</td>\n",
       "      <td>334.821332</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>car_horn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8732 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         slice_file_name    fsID       start  ...  fold  classID             class\n",
       "0       100032-3-0-0.wav  100032    0.000000  ...     5        3          dog_bark\n",
       "1     100263-2-0-117.wav  100263   58.500000  ...     5        2  children_playing\n",
       "2     100263-2-0-121.wav  100263   60.500000  ...     5        2  children_playing\n",
       "3     100263-2-0-126.wav  100263   63.000000  ...     5        2  children_playing\n",
       "4     100263-2-0-137.wav  100263   68.500000  ...     5        2  children_playing\n",
       "...                  ...     ...         ...  ...   ...      ...               ...\n",
       "8727     99812-1-2-0.wav   99812  159.522205  ...     7        1          car_horn\n",
       "8728     99812-1-3-0.wav   99812  181.142431  ...     7        1          car_horn\n",
       "8729     99812-1-4-0.wav   99812  242.691902  ...     7        1          car_horn\n",
       "8730     99812-1-5-0.wav   99812  253.209850  ...     7        1          car_horn\n",
       "8731     99812-1-6-0.wav   99812  332.289233  ...     7        1          car_horn\n",
       "\n",
       "[8732 rows x 8 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uj51hJ9RFwkJ"
   },
   "outputs": [],
   "source": [
    "file_names=[x.split('/')[-1] for x in file_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fEc_junGFdOA"
   },
   "outputs": [],
   "source": [
    "labels=labels[labels['slice_file_name'].isin(file_names)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "id": "tyWEnKb_GFDp",
    "outputId": "72f1e427-fb45-4927-af12-7ca25863c406"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slice_file_name</th>\n",
       "      <th>fsID</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>salience</th>\n",
       "      <th>fold</th>\n",
       "      <th>classID</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>101415-3-0-2.wav</td>\n",
       "      <td>101415</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>101415-3-0-3.wav</td>\n",
       "      <td>101415</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>101415-3-0-8.wav</td>\n",
       "      <td>101415</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>102106-3-0-0.wav</td>\n",
       "      <td>102106</td>\n",
       "      <td>2.243852</td>\n",
       "      <td>3.884477</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>102305-6-0-0.wav</td>\n",
       "      <td>102305</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.611610</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>gun_shot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8676</th>\n",
       "      <td>99180-9-0-2.wav</td>\n",
       "      <td>99180</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>street_music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8677</th>\n",
       "      <td>99180-9-0-36.wav</td>\n",
       "      <td>99180</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>street_music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8678</th>\n",
       "      <td>99180-9-0-48.wav</td>\n",
       "      <td>99180</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>street_music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8679</th>\n",
       "      <td>99180-9-0-49.wav</td>\n",
       "      <td>99180</td>\n",
       "      <td>24.500000</td>\n",
       "      <td>28.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>street_music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8680</th>\n",
       "      <td>99180-9-0-7.wav</td>\n",
       "      <td>99180</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>street_music</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>873 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       slice_file_name    fsID      start  ...  fold  classID         class\n",
       "64    101415-3-0-2.wav  101415   1.000000  ...     1        3      dog_bark\n",
       "65    101415-3-0-3.wav  101415   1.500000  ...     1        3      dog_bark\n",
       "66    101415-3-0-8.wav  101415   4.000000  ...     1        3      dog_bark\n",
       "105   102106-3-0-0.wav  102106   2.243852  ...     1        3      dog_bark\n",
       "106   102305-6-0-0.wav  102305   0.000000  ...     1        6      gun_shot\n",
       "...                ...     ...        ...  ...   ...      ...           ...\n",
       "8676   99180-9-0-2.wav   99180   1.000000  ...     1        9  street_music\n",
       "8677  99180-9-0-36.wav   99180  18.000000  ...     1        9  street_music\n",
       "8678  99180-9-0-48.wav   99180  24.000000  ...     1        9  street_music\n",
       "8679  99180-9-0-49.wav   99180  24.500000  ...     1        9  street_music\n",
       "8680   99180-9-0-7.wav   99180   3.500000  ...     1        9  street_music\n",
       "\n",
       "[873 rows x 8 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "ZMCH-XakGF0C",
    "outputId": "54ecbdf7-7618-485f-f524-8823137e302e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jackhammer          120\n",
       "dog_bark            100\n",
       "air_conditioner     100\n",
       "children_playing    100\n",
       "drilling            100\n",
       "street_music        100\n",
       "engine_idling        96\n",
       "siren                86\n",
       "car_horn             36\n",
       "gun_shot             35\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K7FjFcdMGQAL"
   },
   "outputs": [],
   "source": [
    "classes=list(labels['class'].value_counts().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VPrVyMCAGryC"
   },
   "outputs": [],
   "source": [
    "for cl in classes:\n",
    "  os.mkdir('/content/train/'+cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bPe_SXfAG8oQ"
   },
   "outputs": [],
   "source": [
    "class_dict_map={x:'/content/train/'+x+'/' for x in classes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "B3HFf5xmHt0G",
    "outputId": "9c4ae5b8-f070-4e14-d7b8-d0c77d5c657b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'air_conditioner': '/content/train/air_conditioner/',\n",
       " 'car_horn': '/content/train/car_horn/',\n",
       " 'children_playing': '/content/train/children_playing/',\n",
       " 'dog_bark': '/content/train/dog_bark/',\n",
       " 'drilling': '/content/train/drilling/',\n",
       " 'engine_idling': '/content/train/engine_idling/',\n",
       " 'gun_shot': '/content/train/gun_shot/',\n",
       " 'jackhammer': '/content/train/jackhammer/',\n",
       " 'siren': '/content/train/siren/',\n",
       " 'street_music': '/content/train/street_music/'}"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_dict_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8re-dMIHHye_"
   },
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hF1m7UlSH10v"
   },
   "outputs": [],
   "source": [
    "def return_class(file_name):\n",
    "  cl=labels['class'][labels['slice_file_name']==file_name]\n",
    "  return(cl.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I1gbTHVNIPKe"
   },
   "outputs": [],
   "source": [
    "for file in file_names:\n",
    "  name=file.split('.')[0]+'.jpg'\n",
    "  shutil.move('/content/train/'+name,\n",
    "              class_dict_map[return_class(file)]+name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W41wQaXELGMj"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "wmXQ2jbaJa6P",
    "outputId": "5f9777cc-260f-4498-ab30-d51438c060f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 873 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "WIDTH = 64\n",
    "HEIGHT = 64\n",
    "BATCH_SIZE = 32\n",
    "TRAIN_DIR=r'/content/train'\n",
    "\n",
    "# data prep\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255.,validation_split=0.25)\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=(HEIGHT, WIDTH),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 935
    },
    "colab_type": "code",
    "id": "J60En411LCuw",
    "outputId": "eae9f33a-f615-4190-ce37-be50458001ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 64, 64, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 62, 62, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 62, 62, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 31, 31, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 31, 31, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 31, 31, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 31, 31, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 29, 29, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 29, 29, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 14, 14, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 12, 12, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               2359808   \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 2,679,626\n",
      "Trainable params: 2,679,626\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization,Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "\n",
    "from tensorflow.keras import regularizers, optimizers\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=(64,64,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(optimizers.RMSprop(lr=0.0005, decay=1e-6),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "bV_-i3x8LjxM",
    "outputId": "306f9aab-1f71-48be-ba17-5937347b066d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-59-19e344b3389a>:5: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 27 steps\n",
      "Epoch 1/150\n",
      "27/27 [==============================] - 8s 299ms/step - loss: 2.2249 - accuracy: 0.1237\n",
      "Epoch 2/150\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 1.9756 - accuracy: 0.2652\n",
      "Epoch 3/150\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 1.8586 - accuracy: 0.3103\n",
      "Epoch 4/150\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 1.7640 - accuracy: 0.3757\n",
      "Epoch 5/150\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 1.5523 - accuracy: 0.4471\n",
      "Epoch 6/150\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 1.4550 - accuracy: 0.5137\n",
      "Epoch 7/150\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 1.2370 - accuracy: 0.5493\n",
      "Epoch 8/150\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 1.0604 - accuracy: 0.6195\n",
      "Epoch 9/150\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 0.9369 - accuracy: 0.6813\n",
      "Epoch 10/150\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 0.9347 - accuracy: 0.6611\n",
      "Epoch 11/150\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 0.7430 - accuracy: 0.7444\n",
      "Epoch 12/150\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 0.6761 - accuracy: 0.7527\n",
      "Epoch 13/150\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 0.6058 - accuracy: 0.7836\n",
      "Epoch 14/150\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.5075 - accuracy: 0.8395\n",
      "Epoch 15/150\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.4312 - accuracy: 0.8537\n",
      "Epoch 16/150\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 0.4574 - accuracy: 0.8419\n",
      "Epoch 17/150\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.3940 - accuracy: 0.8597\n",
      "Epoch 18/150\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.3750 - accuracy: 0.8668\n",
      "Epoch 19/150\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 0.3090 - accuracy: 0.8918\n",
      "Epoch 20/150\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.2787 - accuracy: 0.8977\n",
      "Epoch 21/150\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 0.2367 - accuracy: 0.9132\n",
      "Epoch 22/150\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 0.2482 - accuracy: 0.9120\n",
      "Epoch 23/150\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.2450 - accuracy: 0.9251\n",
      "Epoch 24/150\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 0.1988 - accuracy: 0.9322\n",
      "Epoch 25/150\n",
      "27/27 [==============================] - 1s 43ms/step - loss: 0.2032 - accuracy: 0.9310\n",
      "Epoch 26/150\n",
      "27/27 [==============================] - 1s 43ms/step - loss: 0.2259 - accuracy: 0.9191\n",
      "Epoch 27/150\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 0.1538 - accuracy: 0.9489\n",
      "Epoch 28/150\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.1975 - accuracy: 0.9477\n",
      "Epoch 29/150\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 0.1491 - accuracy: 0.9417\n",
      "Epoch 30/150\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 0.1277 - accuracy: 0.9560\n",
      "Epoch 31/150\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 0.1553 - accuracy: 0.9572\n",
      "Epoch 32/150\n",
      "27/27 [==============================] - 1s 43ms/step - loss: 0.1253 - accuracy: 0.9631\n",
      "Epoch 33/150\n",
      "27/27 [==============================] - 1s 45ms/step - loss: 0.1050 - accuracy: 0.9655\n",
      "Epoch 34/150\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 0.1274 - accuracy: 0.9584\n",
      "Epoch 35/150\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.1130 - accuracy: 0.9620\n",
      "Epoch 36/150\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.0653 - accuracy: 0.9750\n",
      "Epoch 37/150\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.0915 - accuracy: 0.9703\n",
      "Epoch 38/150\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.0767 - accuracy: 0.9774\n",
      "Epoch 39/150\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.0990 - accuracy: 0.9667\n",
      "Epoch 40/150\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.1024 - accuracy: 0.9667\n",
      "Epoch 41/150\n",
      "27/27 [==============================] - 1s 43ms/step - loss: 0.0542 - accuracy: 0.9857\n",
      "Epoch 42/150\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.1292 - accuracy: 0.9655\n",
      "Epoch 43/150\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 0.0245 - accuracy: 0.9917\n",
      "Epoch 44/150\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.0817 - accuracy: 0.9715\n",
      "Epoch 45/150\n",
      "27/27 [==============================] - 1s 43ms/step - loss: 0.0595 - accuracy: 0.9822\n",
      "Epoch 46/150\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.1035 - accuracy: 0.9691\n",
      "Epoch 47/150\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 0.0522 - accuracy: 0.9869\n",
      "Epoch 48/150\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.0494 - accuracy: 0.9869\n",
      "Epoch 49/150\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 0.1100 - accuracy: 0.9655\n",
      "Epoch 50/150\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 0.0281 - accuracy: 0.9881\n",
      "Epoch 51/150\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.0888 - accuracy: 0.9738\n",
      "Epoch 52/150\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.0307 - accuracy: 0.9869\n",
      "Epoch 53/150\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.0812 - accuracy: 0.9762\n",
      "Epoch 54/150\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.0403 - accuracy: 0.9822\n",
      "Epoch 55/150\n",
      "27/27 [==============================] - 1s 43ms/step - loss: 0.0222 - accuracy: 0.9941\n",
      "Epoch 56/150\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 0.0431 - accuracy: 0.9857\n",
      "Epoch 57/150\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.0868 - accuracy: 0.9810\n",
      "Epoch 58/150\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 0.0926 - accuracy: 0.9798\n",
      "Epoch 59/150\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.0331 - accuracy: 0.9893\n",
      "Epoch 60/150\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.1472 - accuracy: 0.9762\n",
      "Epoch 61/150\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.0240 - accuracy: 0.9929\n",
      "Epoch 62/150\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.0149 - accuracy: 0.9964\n",
      "Epoch 63/150\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.0727 - accuracy: 0.9798\n",
      "Epoch 64/150\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.0743 - accuracy: 0.9798\n",
      "Epoch 65/150\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 0.0486 - accuracy: 0.9857\n",
      "Epoch 66/150\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.0443 - accuracy: 0.9905\n",
      "Epoch 67/150\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 0.0603 - accuracy: 0.9798\n",
      "Epoch 68/150\n",
      "27/27 [==============================] - 1s 43ms/step - loss: 0.0395 - accuracy: 0.9861\n",
      "Epoch 69/150\n",
      "27/27 [==============================] - 1s 40ms/step - loss: 0.0741 - accuracy: 0.9798\n",
      "Epoch 70/150\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.0372 - accuracy: 0.9869\n",
      "Epoch 71/150\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.0242 - accuracy: 0.9893\n",
      "Epoch 72/150\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 0.0076 - accuracy: 0.9976\n",
      "Epoch 73/150\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.1096 - accuracy: 0.9774\n",
      "Epoch 74/150\n",
      "27/27 [==============================] - 1s 46ms/step - loss: 0.0198 - accuracy: 0.9941\n",
      "Epoch 75/150\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.0189 - accuracy: 0.9952\n",
      "Epoch 76/150\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 0.0185 - accuracy: 0.9941\n",
      "Epoch 77/150\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.0547 - accuracy: 0.9893\n",
      "Epoch 78/150\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.0167 - accuracy: 0.9929\n",
      "Epoch 79/150\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.0917 - accuracy: 0.9857\n",
      "Epoch 80/150\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.0085 - accuracy: 0.9964\n",
      "Epoch 81/150\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.0130 - accuracy: 0.9964\n",
      "Epoch 82/150\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 0.0721 - accuracy: 0.9822\n",
      "Epoch 83/150\n",
      "27/27 [==============================] - 1s 43ms/step - loss: 0.0179 - accuracy: 0.9952\n",
      "Epoch 84/150\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 0.0805 - accuracy: 0.9834\n",
      "Epoch 85/150\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 0.0130 - accuracy: 0.9952\n",
      "Epoch 86/150\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.0264 - accuracy: 0.9917\n",
      "Epoch 87/150\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 0.0322 - accuracy: 0.9917\n",
      "Epoch 88/150\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 0.0425 - accuracy: 0.9917\n",
      "Epoch 89/150\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.0150 - accuracy: 0.9964\n",
      "Epoch 90/150\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.0119 - accuracy: 0.9941\n",
      "Epoch 91/150\n",
      "27/27 [==============================] - 1s 40ms/step - loss: 0.0849 - accuracy: 0.9869\n",
      "Epoch 92/150\n",
      "27/27 [==============================] - 1s 43ms/step - loss: 0.0434 - accuracy: 0.9905\n",
      "Epoch 93/150\n",
      "27/27 [==============================] - 1s 40ms/step - loss: 0.0145 - accuracy: 0.9964\n",
      "Epoch 94/150\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 0.0479 - accuracy: 0.9857\n",
      "Epoch 95/150\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.0293 - accuracy: 0.9941\n",
      "Epoch 96/150\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 0.0243 - accuracy: 0.9952\n",
      "Epoch 97/150\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 0.0422 - accuracy: 0.9869\n",
      "Epoch 98/150\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 0.0192 - accuracy: 0.9905\n",
      "Epoch 99/150\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.0403 - accuracy: 0.9893\n",
      "Epoch 100/150\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.0284 - accuracy: 0.9919\n",
      "Epoch 101/150\n",
      "27/27 [==============================] - 1s 40ms/step - loss: 0.0432 - accuracy: 0.9917\n",
      "Epoch 102/150\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.0055 - accuracy: 0.9976\n",
      "Epoch 103/150\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 0.0240 - accuracy: 0.9905\n",
      "Epoch 104/150\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.0641 - accuracy: 0.9917\n",
      "Epoch 105/150\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.0428 - accuracy: 0.9893\n",
      "Epoch 106/150\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 0.0092 - accuracy: 0.9976\n",
      "Epoch 107/150\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.0102 - accuracy: 0.9964\n",
      "Epoch 108/150\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.0230 - accuracy: 0.9952\n",
      "Epoch 109/150\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.0682 - accuracy: 0.9857\n",
      "Epoch 110/150\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 0.0253 - accuracy: 0.9952\n",
      "Epoch 111/150\n",
      "27/27 [==============================] - 1s 43ms/step - loss: 0.0257 - accuracy: 0.9917\n",
      "Epoch 112/150\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.0076 - accuracy: 0.9964\n",
      "Epoch 113/150\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.0114 - accuracy: 0.9976\n",
      "Epoch 114/150\n",
      "27/27 [==============================] - 1s 44ms/step - loss: 0.0290 - accuracy: 0.9917\n",
      "Epoch 115/150\n",
      "27/27 [==============================] - 1s 45ms/step - loss: 0.0223 - accuracy: 0.9952\n",
      "Epoch 116/150\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 0.0694 - accuracy: 0.9893\n",
      "Epoch 117/150\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 0.0029 - accuracy: 0.9976\n",
      "Epoch 118/150\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.0748 - accuracy: 0.9893\n",
      "Epoch 119/150\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 0.0229 - accuracy: 0.9952\n",
      "Epoch 120/150\n",
      "27/27 [==============================] - 1s 43ms/step - loss: 0.0118 - accuracy: 0.9942\n",
      "Epoch 121/150\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 0.0132 - accuracy: 0.9976\n",
      "Epoch 122/150\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.0188 - accuracy: 0.9941\n",
      "Epoch 123/150\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.0444 - accuracy: 0.9952\n",
      "Epoch 124/150\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 0.0294 - accuracy: 0.9929\n",
      "Epoch 125/150\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 0.0210 - accuracy: 0.9952\n",
      "Epoch 126/150\n",
      "27/27 [==============================] - 1s 40ms/step - loss: 0.0805 - accuracy: 0.9905\n",
      "Epoch 127/150\n",
      "27/27 [==============================] - 1s 40ms/step - loss: 0.0030 - accuracy: 0.9988\n",
      "Epoch 128/150\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.0070 - accuracy: 0.9976\n",
      "Epoch 129/150\n",
      "27/27 [==============================] - 1s 43ms/step - loss: 0.0292 - accuracy: 0.9964\n",
      "Epoch 130/150\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 0.0190 - accuracy: 0.9952\n",
      "Epoch 131/150\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.0222 - accuracy: 0.9941\n",
      "Epoch 132/150\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.0422 - accuracy: 0.9952\n",
      "Epoch 133/150\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.0320 - accuracy: 0.9893\n",
      "Epoch 134/150\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 0.0189 - accuracy: 0.9964\n",
      "Epoch 135/150\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.0029 - accuracy: 0.9988\n",
      "Epoch 136/150\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.0248 - accuracy: 0.9905\n",
      "Epoch 137/150\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.0389 - accuracy: 0.9929\n",
      "Epoch 138/150\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 0.0215 - accuracy: 0.9941\n",
      "Epoch 139/150\n",
      "27/27 [==============================] - 1s 43ms/step - loss: 0.0755 - accuracy: 0.9917\n",
      "Epoch 140/150\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 6.2523e-05 - accuracy: 1.0000\n",
      "Epoch 141/150\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 0.0685 - accuracy: 0.9893\n",
      "Epoch 142/150\n",
      "27/27 [==============================] - 1s 43ms/step - loss: 0.0064 - accuracy: 0.9964\n",
      "Epoch 143/150\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 2.2307e-04 - accuracy: 1.0000\n",
      "Epoch 144/150\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.0938 - accuracy: 0.9834\n",
      "Epoch 145/150\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 0.0013 - accuracy: 0.9988\n",
      "Epoch 146/150\n",
      "27/27 [==============================] - 1s 44ms/step - loss: 0.0387 - accuracy: 0.9893\n",
      "Epoch 147/150\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.0358 - accuracy: 0.9929\n",
      "Epoch 148/150\n",
      "27/27 [==============================] - 1s 43ms/step - loss: 0.0018 - accuracy: 0.9988\n",
      "Epoch 149/150\n",
      "27/27 [==============================] - 1s 42ms/step - loss: 0.0530 - accuracy: 0.9929\n",
      "Epoch 150/150\n",
      "27/27 [==============================] - 1s 41ms/step - loss: 0.0016 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f15897d96a0>"
      ]
     },
     "execution_count": 59,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "\n",
    "model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    epochs=150\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ML9Id0qnL6xX"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Audio_data_cnn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
